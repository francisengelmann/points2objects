<!DOCTYPE html>
<html>

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>From Points to Multi-Object 3D Reconstruction</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="./w3.css">
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-1168479-13"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-1168479-13');
  </script>

</head>

<body>

<!-- Links (sit on top) -->
<div class="w3-top" align="center">
  <div class="w3-row w3-padding w3-black">
    <div align="center">
    <div class="w3-col s3"><a href="#publication" class="w3-button w3-block w3-black">Publication</a></div>
    <div class="w3-col s3"><a href="#code" class="w3-button w3-block w3-black">Code</a></div>
    <div class="w3-col s3"><a href="#poster" class="w3-button w3-block w3-black">Poster</a></div>
    <div class="w3-col s3"><a href="#bibtex" class="w3-button w3-block w3-black">BibTeX</a></div>
  </div>
  </div>
</div>

<br><br><br>

<h4 align="center" id="title">Points2Objects:</h4>
<h3 align="center" id="title">From Points to Multi-Object 3D Reconstruction</h3>
  <p align="center" class="center_text" id="authors">
    <a target="_blank" href="http://francisengelmann.github.io/">Francis Engelmann</a>&nbsp;&nbsp;&nbsp;&nbsp;
    <a target="_blank" href="http://www.krematas.com/">Konstantinos Rematas</a>&nbsp;&nbsp;&nbsp;&nbsp;
    <a target="_blank" href="https://www.vision.rwth-aachen.de/person/1/">Bastian Leibe</a>&nbsp;&nbsp;&nbsp;&nbsp;
    <a target="_blank" href="https://sites.google.com/view/vittoferrari">Vittorio Ferrari</a>&nbsp;&nbsp;&nbsp;&nbsp;
  </ul>
  </p>

  <p class="center_text" align="center">RWTH Aachen University, Computer Vision Group</p>
  <p class="center_text" align="center">Google Research, Zurich</p>

  <p align="center" id="title">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2021.</p>


<br>
</span>
<div class="w3-container" id="paper">
  <div class="w3-content" style="max-width:850px">
    <!--<h3><b>Abstract</b></h3>-->
    <br><center><img src="teaser-multi-object.jpg" style="max-width:75%" /></center><br>
    <p style="text-align: justify; text-justify: inter-word;">
We propose a method to detect and reconstruct multiple 3D objects from a single RGB image. The key idea is to optimize for detection, alignment and shape jointly over all objects in the RGB image, while focusing on realistic and physically plausible reconstructions. To this end, we propose a keypoint detector that localizes objects as center points and directly predicts all object properties, including 9-DoF bounding boxes and 3D shapes -- all in a single forward pass.
    </p>

    <h3 class="w3-left-align" id="model"><b>Model</b></h3>
    <center>
      <img src="model.png" style="max-width:100%" />
    </center>
    <p style="text-align: justify; text-justify: inter-word;">
Overview of the proposed approach: Given a single RGB image, our model detects object centers as key-points in a heatmap. The network directly predicts shape exemplars and 9-DoF bounding boxes jointly for all objects in the scene. The collision loss favors non-intersecting reconstructions. Our method predicts lightweight, realistic and physically plausible reconstructions in a single pass.
</p>

<h3 class="w3-left-align" id="model"><b>Results</b> on synthetic images.</h3>
<center>
  <img src="synthetic_results.jpg" style="max-width:100%" />
</center>
<br>
<h3 class="w3-left-align" id="model"><b>Results</b> on real images.</h3>
<center>
  <img src="real_results.png" style="max-width:100%" />
</center>
<br>

<h3 class="w3-left-align" id="publication"><b>Publication</b></h3>
<center>
  <a href="https://arxiv.org/pdf/2012.11575.pdf"><img src="paper.png" style="max-width:100%; border: 0.5px solid gray" /></a>
</center><br>

    <h3 class="w3-left-align" id="poster"><b>Poster</b></h3>
    <center>
      <a href="https://francisengelmann.github.io/points2objects/cvpr21_points2objects_poster.pdf"><img src="poster.png" style="max-width:100%; border: 0.5px solid gray" /></a>
    </center><br>

    <h3 class="w3-left-align" id="code"><b>Code and Datasets</b></h3>
    Tensorflow 2 Code <a href="https://github.com/tensorflow/graphics/tree/master/tensorflow_graphics/projects/points_to_3Dobjects">[link]</a> </br>
    Multi-object synthetic CoReNet dataset <a href="https://github.com/google-research/corenet#datasets">[link]</a>
    <br>
    <br>

    <h3 class="w3-left-align" id="bibtex"><b>BibTeX</b></h3>
    <pre class="w3-panel w3-leftbar w3-light-grey" style="white-space: pre-wrap; font-family: monospace; font-size: 12px">

@inproceedings{engelmann2020points,
  author={Engelmann, Francis and Rematas, Konstantinos and Leibe, Bastian and Ferrari, Vittorio},
  title={{From Points to Multi-Object 3D Reconstruction}},
  booktitle = {{IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}},
  year = {2021}
}
    </pre>
  </div>

</div>

</br>
</br>
</br>

</body>
</html>
